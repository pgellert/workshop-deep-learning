{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Intro to Deep Learning 2",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pgellert/workshop-deep-learning/blob/master/Copy_of_Intro_to_Deep_Learning_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lDupTkzbZity",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Intro to Deep Learning 2\n",
        "\n",
        "This is the notebook accompanying the second Hackers at Cambridge Deep Learning workshop.\n",
        "In this workshop, you'll implement your own *convolutional neural network* using the **Keras** deep learning framework.\n"
      ]
    },
    {
      "metadata": {
        "id": "1r64tZrRZ8OP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, let's import dependencies:"
      ]
    },
    {
      "metadata": {
        "id": "Rzn5B0GbZfIC",
        "colab_type": "code",
        "outputId": "c45d48b3-f46e-4c80-9284-ce148c489ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#import the keras functions\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from  keras.utils import to_categorical as OneHotEncode\n",
        "from keras import backend as K\n",
        "#numpy to manipulate arrays\n",
        "import numpy as np\n",
        "#to visualise outputs\n",
        "import matplotlib.pyplot as plt\n",
        "#import the MNIST dataset\n",
        "from keras.datasets import mnist\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OJZ_1oN4cAVX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading In the Data:\n",
        "\n",
        "As in the first workshop, you'll want to load in the data, using a nice **load data()** function.\n",
        "\n",
        "First, we'll reshape the input x_train and x_test into a *(num_examples, width, height, number of channels)* dimensional array.\n",
        "\n",
        "For MNIST, the input image is of size 28x28 and it is greyscale so number of channels =1. \n",
        "\n",
        "We then want to normalise the values - since pixels are in range [0...255], divide by 255 to get them in range [0...1]\n",
        "\n",
        "Finally, we want to **one-hot encode** our output labels y_train and y_test.\n",
        "\n",
        "### Useful Functions:\n",
        "    A = np.reshape(A, (b,c,d)) # reshapes A into a b x c x d array - (b,c,d) = tuple of dimensions\n",
        "    \n",
        "    OneHotEncode(input array, num_classes ) #returns the one hot encoded output\n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "LQQF2bVhcBOU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  #Load in the data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "num_classes = 10\n",
        "num_train_examples = x_train.shape[0]\n",
        "num_test_examples = x_test.shape[0]\n",
        "\n",
        "# reshape array so dims are (num_examples, 28, 28, 1)\n",
        "x_train = np.reshape(x_train, (num_train_examples, 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (num_test_examples, 28, 28, 1))\n",
        "\n",
        "# divide both arrays by 255 (to normalise from [0..255] to [0..1])\n",
        "x_train= x_train/255\n",
        "x_test = x_test/255\n",
        "\n",
        "#one hot encode \n",
        "y_train = OneHotEncode(y_train, num_classes)\n",
        "y_test = OneHotEncode(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P43cvuiMarfY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating the model:\n",
        "          \n",
        "Keras is a high level deep learning framework that makes it really easy to create our own model - in this workshop we will be using the **Sequential API**. \n",
        "\n",
        "There are four steps to creating a model in Keras:\n",
        " * Define \n",
        " * Compile\n",
        " * Fit\n",
        " * Evaluate\n",
        " \n",
        " \n",
        " We'll look at each stage in turn:"
      ]
    },
    {
      "metadata": {
        "id": "46qW6kLAkipt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the model:\n",
        "\n",
        "This is where we specify the layers in our model.\n",
        "\n",
        "We are using the Sequential API so to start we'll define the model:\n",
        "\n",
        "      model = Sequential()\n",
        "      \n",
        "This is the base to start on. We can then sequentially add the layers to the model using \n",
        "\n",
        "            model.add(layer object)\n",
        "      \n",
        " the layerr objects are either\n",
        " \n",
        " * Conv2D() (convolution layer) \n",
        " * MaxPooling2D()\n",
        " * Flatten() - this takes the output of the last layer and flattens it to pass into a fully-connected layer\n",
        " * Dense() - this is a fully-connected layer\n",
        " \n",
        " so you might have:\n",
        " \n",
        "          model = Sequential()\n",
        "          model.add(Dense(units=128, activation='relu'))\n",
        "          model.add(Dense(units=10, activation='softmax'))\n",
        " \n",
        " and now  *model* would be a 2 layer neural network.\n",
        " \n",
        " The layers take in different arguments - in the example above Dense() took arguments the number of neurons (128, 10 respectively) and the activation function used. \n",
        " \n",
        " To summarise the main arguments passed in: \n",
        "       \n",
        "       input_shape = __ #for the first layer\n",
        "\n",
        " \n",
        "[Conv2D](https://keras.io/layers/convolutional/#conv2d)takes in parameters:\n",
        "\n",
        "      kernel_size=(f,f) #specifying an fxf filter typically f=1,3,5,7\n",
        "      strides=(a,a ) #specifying a stride of a (this is typically 1)\n",
        "      padding='same' # this is either 'same' (zero-pad) or 'valid' (no padding)\n",
        "      filters=x #x is number of filters\n",
        "      activation='relu'\n",
        "      \n",
        "[MaxPooling2D](https://keras.io/layers/pooling/#maxpooling2d) has\n",
        "      \n",
        "      pool_size=(2, 2) # the size of patch used (2x2 is default for pretty much everything)\n",
        "      \n",
        "[Dense](https://keras.io/layers/core/#dense) has \n",
        "\n",
        "              units=n # number of neurons in layer\n",
        "              activation = __ #  'relu', 'softmax', 'sigmoid', 'tanh' are possible activations\n",
        "              "
      ]
    },
    {
      "metadata": {
        "id": "y5sMido3anfY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initCNN(input_shape, num_classes):\n",
        "    #initialise a model\n",
        "    model = model = Sequential()\n",
        "    model.add(Conv2D(input_shape=input_shape, kernel_size=(3,3),strides=(1,1), padding='same', filters=16, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(kernel_size=(3,3),strides=(1,1), padding='same', filters=32, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    model.add(Dense(units=num_classes, activation='softmax'))\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2AwmpwYPPWQO",
        "colab_type": "code",
        "outputId": "6f84541b-3095-46a5-acec-7d9f2bb19186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "convNet = initCNN(x_train[0].shape, num_classes)\n",
        "convNet.summary() #print the description of the layers in the model"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               200832    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 206,922\n",
            "Trainable params: 206,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MLlT9HE3o2-w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compiling the Model:\n",
        "\n",
        "This is where we specify the loss function we are using, the optimizer we are using and the metrics we want to track when training, as well as a bunch of other information pertaining to training.\n",
        "\n",
        "        model.compile(arguments)\n",
        "        \n",
        " where the arguments we are interested in are\n",
        " \n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer='sgd',\n",
        "       metrics=['accuracy']\n",
        "       \n",
        "       \n",
        "       \n",
        " 'sgd' stands for Stochastic Gradient Descent - this is a variant of gradient descent where we feed the training data to the model in **batches** rather than giving it all at once"
      ]
    },
    {
      "metadata": {
        "id": "03QAcRS2ebkz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "convNet.compile(loss='categorical_crossentropy',\n",
        "  optimizer='sgd',\n",
        "   metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dboac99SpXv_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fitting the model\n",
        "\n",
        "This is where we actually train our model, feel free to alter the hyperparameters (e.g. number of epochs to train it for longer etc.)\n",
        "\n",
        "      model.fit(x=, y=, epochs=, batch_size=, validation_data=(x_test, y_test))\n",
        "\n",
        "x, y are the training set\n",
        "\n",
        "The validation_data argument takes as input the **validation dataset**. Here we have split the dataset into train:test split, however typically we would split into train:validation:test - and the purpose of the validation data is to tune the hyperparameters (so we try to maximise performance on the validation data set).\n",
        "\n",
        "For today, we'll just use x_test, y_test, though I encourage you (as an extension) to split the data up so you have a separate validation set.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZtX63q0IfOH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "b8e9ecac-d831-4d30-977f-7da0dc1bc2b4"
      },
      "cell_type": "code",
      "source": [
        "#fit the model \n",
        "convNet.fit(x=x_train, y=y_train, epochs=8, batch_size=32, validation_data=(x_test, y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/8\n",
            "60000/60000 [==============================] - 14s 234us/step - loss: 0.5368 - acc: 0.8420 - val_loss: 0.2062 - val_acc: 0.9346\n",
            "Epoch 2/8\n",
            "60000/60000 [==============================] - 12s 206us/step - loss: 0.1573 - acc: 0.9526 - val_loss: 0.1154 - val_acc: 0.9648\n",
            "Epoch 3/8\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.1043 - acc: 0.9688 - val_loss: 0.0774 - val_acc: 0.9761\n",
            "Epoch 4/8\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0816 - acc: 0.9752 - val_loss: 0.0648 - val_acc: 0.9796\n",
            "Epoch 5/8\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0684 - acc: 0.9785 - val_loss: 0.0564 - val_acc: 0.9810\n",
            "Epoch 6/8\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0594 - acc: 0.9819 - val_loss: 0.0545 - val_acc: 0.9821\n",
            "Epoch 7/8\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0526 - acc: 0.9835 - val_loss: 0.0480 - val_acc: 0.9829\n",
            "Epoch 8/8\n",
            "60000/60000 [==============================] - 12s 204us/step - loss: 0.0469 - acc: 0.9852 - val_loss: 0.0487 - val_acc: 0.9842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1a37c64fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Ze1fQ34RqNhL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model\n",
        "\n",
        "Finally, we can use the model.evaluate function to evaluate how well the model has done on the test set. Here x, y are the test set inputs/labels respectively.\n",
        "\n",
        "        loss, accuracy = model.evaluate(x=, y=)\n",
        "        \n",
        "   "
      ]
    },
    {
      "metadata": {
        "id": "LcIyx1IwhYii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46545eee-e06e-412f-da64-1fbcc6768f09"
      },
      "cell_type": "code",
      "source": [
        "# calculate the accuracy\n",
        "loss, accuracy = convNet.evaluate(x=x_test, y=y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 80us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JrSiGGSVOjQk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Â Visualise the activations:\n",
        "\n",
        "\n",
        "If you're curious to see the internals of a CNN, this code prints out the intermediate outputs of the network."
      ]
    },
    {
      "metadata": {
        "id": "iq41NFsKOqHC",
        "colab_type": "code",
        "outputId": "fc9fc078-f791-4913-fc18-44672eb1c375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "cell_type": "code",
      "source": [
        "#choose a random integer\n",
        "image = x_test[np.random.randint(0,x_test.shape[0])]\n",
        "image = np.reshape(image, (1,28,28,1))\n",
        "\n",
        "# this is a lambda function that takes input convNet.layers[0].input and returns a list of the outputs for each of the layers.\n",
        "get_layers_outputs = K.function([convNet.layers[0].input],\n",
        "                                  [convNet.layers[i].output for i in range(len(convNet.layers))])\n",
        "\n",
        "\n",
        "layers_outputs = get_layers_outputs([image])\n",
        "\n",
        "\n",
        "#plot the outputs\n",
        "fig, ax = plt.subplots(1,1+len(layers_outputs))\n",
        "ax[0].imshow(image[0,:,:,0], cmap='gray')\n",
        "\n",
        "for i, output in enumerate(layers_outputs):\n",
        "  if len(output.shape)==4:\n",
        "    #pick random activation map\n",
        "    ax[i+1].imshow(output[0,:,:,np.random.randint(0,output.shape[-1])], cmap='gray')\n",
        "  else: #dense layer\n",
        "    ax[i+1].imshow(output.T,cmap='gray')\n",
        "\n",
        "print(\"The predicted output is: \" + str(np.argmax(convNet.predict(image))))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The predicted output is: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd0AAAFOCAYAAADDz8eDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEdkJky4REZGdMOkSERHZyf8DFpvwdIX7kH8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a319014a8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7xMleUKkwFRE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NqrH_Ss0zkOb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}